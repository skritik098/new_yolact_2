import numpy as np
from skimage.util.shape import view_as_windows
import utils.img_utils as img_utils

#Turns a list of bounding boxes into a heatmap for further processing
def add_heat(heatmap, bbox_list):
    # Iterate through list of bboxes
    for box in bbox_list:
        # Add += 1 for all pixels inside each bbox
        # Assuming each "box" takes the form ((x1, y1), (x2, y2))
        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1
    # Return updated heatmap
    return heatmap# Iterate through list of bboxes

#Applies a threshold to the heatmap generated by add_heat()
def apply_threshold(heatmap, threshold):
    # Zero out pixels below the threshold
    heatmap[heatmap <= threshold] = 0
    # Return thresholded map
    return heatmap

def sum_heatmap(heatmaps_list, thresh):
    smooth_heatmap = 0
    #Sum the hot pixel values in the heatmap upto a maximum of smooth_count
    for i in range(len(heatmaps_list)):
        smooth_heatmap += heatmaps_list[i]
    #Apply the threshold before returning the heatmap
    return apply_threshold(smooth_heatmap, thresh)

#Create views of image for input into the neural network
#http://scikit-image.org/docs/stable/api/skimage.util.html#view-as-windows
def create_views(img, window_size, xy_overlap, xlim, ylim, window_scale):
    views = []
    for idx, scale in enumerate(window_scale):
        #Determine step size based on overlap
        nx_pix_per_step = np.int(window_scale[idx]*window_size[0]*(1 - xy_overlap[0]))
        ny_pix_per_step = np.int(window_scale[idx]*window_size[1]*(1 - xy_overlap[1]))
        #Generate views one channel at a time
        image_views0 = view_as_windows(img[ylim[idx][0]:ylim[idx][1],xlim[idx][0]:xlim[idx][1],0], 
                                       (window_scale[idx]*window_size[0], window_scale[idx]*window_size[1]),
                                       (nx_pix_per_step, ny_pix_per_step))
        image_views1 = view_as_windows(img[ylim[idx][0]:ylim[idx][1],xlim[idx][0]:xlim[idx][1],1], 
                                       (window_scale[idx]*window_size[0], window_scale[idx]*window_size[1]),
                                       (nx_pix_per_step, ny_pix_per_step))
        image_views2 = view_as_windows(img[ylim[idx][0]:ylim[idx][1],xlim[idx][0]:xlim[idx][1],2], 
                                       (window_scale[idx]*window_size[0], window_scale[idx]*window_size[1]),
                                       (nx_pix_per_step, ny_pix_per_step))
        #Stack the channels back into an image
        image_views = np.stack((image_views0,image_views1,image_views2), -1)
        #Reshape the views to (n_samples, image height, image width, channels)
        image_views = np.reshape(image_views, (-1, int(window_scale[idx]*window_size[0]), 
                                               int(window_scale[idx]*window_size[1]),3))
        #Resize the images
        image_views = img_utils.resize_set(image_views, 32)
        #Append the image view to the views array for each scale
        views.extend(image_views)
    #print("Shape of views is:", np.asarray(views).shape)
    return np.asarray(views)

#Create a list of window coordinates to filter for positive predictions
def slide_window(img, x_start_stop=[None, None], y_start_stop=[None, None], 
                    xy_window=(64, 64), xy_overlap=(0.5, 0.5)):
    # If x and/or y start/stop positions not defined, set to image size
    if x_start_stop[0] == None:
        x_start_stop[0] = 0
    if x_start_stop[1] == None:
        x_start_stop[1] = img.shape[1]
    if y_start_stop[0] == None:
        y_start_stop[0] = 0
    if y_start_stop[1] == None:
        y_start_stop[1] = img.shape[0]
    # Compute the span of the region to be searched    
    xspan = x_start_stop[1] - x_start_stop[0]
    yspan = y_start_stop[1] - y_start_stop[0]
    # Compute the number of pixels per step in x/y
    nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))
    ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))
    # Compute the number of windows in x/y
    nx_buffer = np.int(xy_window[0]*(xy_overlap[0]))
    ny_buffer = np.int(xy_window[1]*(xy_overlap[1]))
    nx_windows = np.int((xspan-nx_buffer)/nx_pix_per_step) 
    ny_windows = np.int((yspan-ny_buffer)/ny_pix_per_step) 
    # Initialize a list to append window positions to
    window_list = []
    # Loop through finding x and y window positions
    # Note: you could vectorize this step, but in practice
    # you'll be considering windows one by one with your
    # classifier, so looping makes sense
    for ys in range(ny_windows):
        for xs in range(nx_windows):
            # Calculate window position
            startx = xs*nx_pix_per_step + x_start_stop[0]
            endx = startx + xy_window[0]
            starty = ys*ny_pix_per_step + y_start_stop[0]
            endy = starty + xy_window[1]
            # Append window position to list
            window_list.append(((startx, starty), (endx, endy)))
    # Return the list of windows
    return window_list

#Perform prediction on views generated from image
def search_windows(views, model):   
    #Generate predictions for entire batch of views
    predictions = model.predict(views, batch_size = len(views))
    return predictions.reshape(-1)

